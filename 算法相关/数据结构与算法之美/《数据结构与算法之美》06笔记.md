[TOC]

# 关于我的仓库

- 这篇文章是我为面试准备的学习总结中的一篇
- 我将准备面试中找到的所有学习资料，写的Demo，写的博客都放在了这个仓库里[iOS-Engineer-Interview](https://github.com/KevinAshen/iOS-Engineer-Interview)
- 欢迎star👏👏
- 其中的博客在简书，CSDN都有发布
- 博客中提到的相关的代码Demo可以在仓库里相应的文件夹里找到

# 前言

- 该系列为学习《数据结构与算法之美》的系列学习笔记
- 总结规律为一周一更，内容包括其中的重要知识带你，以及课后题的解答
- 算法的学习学与刷题并进，希望能真正养成解算法题的思维
- LeetCode刷题仓库：[LeetCode-All-In](https://github.com/KevinAshen/LeetCode-All-In)
- 多说无益，你应该开始打代码了

# 06讲链表(上):如何实现LRU缓存淘汰算法

- 常见缓存淘汰策略：先进先出策略FIFO(First In，First Out)、最少使用策略LFU(Least Frequently Used)、最近最少使用策略LRU(Least Recently Used)。
- 删除指定节点：由于删除节点需要使用前一个节点的next指针，所以对于单链表，在执行这样的删除，插入【前一个插入】的时候，都需要遍历链表
- 而双向链表对此就很有优势，包括对于有序链表查找，由于可以判定往后还是往前【此处存疑，怎么从中间开始？】
- 对于执行较慢的程序，可以通过消耗更多的内存(空间换时间)来进行优化;而消耗过多内存的程序，可以 通过消耗更多的时间(时间换空间)来降低内存的消耗。 ![BFB09C85-132D-417E-A24F-0D8F707D2F59](http://ww3.sinaimg.cn/large/006tNc79ly1g5xb9gmmooj31fo0k8wtz.jpg)
- 在实现上使用的是连续的内存空间，可以借助CPU的缓存机制，预读数组中的数据，所以访问效率更高。而 链表在内存中并不是连续存储，所以对CPU缓存不友好，没办法有效预读。CPU在从内存读取数据的时候，会先把读取到的数据加载到CPU的缓存中。而CPU每次从内存读取数据并不是只读取那个特定 要访问的地址，而是读取一个数据块并保存到CPU缓存中，然后下次访问内存数据的时候就会先从CPU缓存开始查找，如果找到就不需要再从内存中取。这样就实现了比内存访问速度更快的机制，也就是CPU缓存存在的意义:为了弥补内存访问速度过慢与CPU执行速度快之间的差异而引入。对于数组来说，存储空间是连续的，所以在加载某个下标的时候可以把以后的几个下标元素也加载到CPU缓存这样执行速度会 快于存储空间不连续的链表存储。
- 链表本身没有大小的限制，天然地支持动态扩容，我觉得这也是它与数组最大的区 别。如果我们用ArrayList存储了了1GB大小的数据，这个时候已经没有空闲空间了，当我们再插入数据 的时候，ArrayList会申请一个1.5GB大小的存储空间，并且把原来那1GB的数据拷⻉到新申请的空间上。听起来是不是就很耗时?

## 实现LRU缓存淘汰算法

- 维护一个单向链表，越靠近尾节点越是远古且不常用
- 插入数据时：
  - 缓存已满，直接删除尾节点，将新数据插入头节点
  - 缓存不满：
    - 找到的该数据，删除原来的，在头节点加入
    - 找不到，直接在头节点加入

## 课后题：如何判断一个字符串是否是回文字符串的问题，我想你应该听过，我们今天的思题目就是基于这个问题的改造版本。如果字符串是通过单链表来存储的，那该如何来判断是一个回文串呢?你有什么好的解决思路呢?相应的时间空间复杂度又是多少呢?

```c++
/**
 * Definition for singly-linked list.
 * public class ListNode {
 *     int val;
 *     ListNode next;
 *     ListNode(int x) { val = x; }
 * }
 */
class Solution {
  public boolean isPalindrome(ListNode head) {
    if (head == null || head.next == null) {
      return true;
    }

    ListNode prev = null;
    ListNode slow = head;
    ListNode fast = head;

    while (fast != null && fast.next != null) {
      //pre：前一个
      //slow：慢指针&&后一段链表的开头
      //fast：快指针，边界工具人
      //操作就是要把慢指针经过的逆置过来，所以让pre作为前一个，slow作为当前工具人，使用next去记录下一个，就是slow的下一位
      //变换时，先把前面的逆过来，slow再往下走
      fast = fast.next.next;
      ListNode next = slow.next;
      slow.next = prev;
      prev = slow;
      slow = next;
    }

    if (fast != null) {
      //！=NULL的这个情况就是奇数的情况，此时，slow工具人站在中间，pre就位，因此要让slow往前一个
      slow = slow.next;
    }

    while (slow != null) {
      if (slow.val != prev.val) {
        return false;
      }
      slow = slow.next;
      prev = prev.next;
    }

    return true;
  }
}
```

- 先通过快慢指针找到中点，此时链表分为两部分，把前半部分逆置，然后比较两列

# 02讲如何抓住重点，系统高效地学习数据结构与算法
- 数据结构是为算法服务的，算法要作用在特定的数据结构之上。
- 复杂度分析对于学习算法有很大的用处，✊学好

![img](http://ww3.sinaimg.cn/large/006tNc79ly1g5udrhrw9fj30u01tau05.jpg)

- 十个数据结构：数组、链表、栈、队列、散列表、二叉树、堆、跳表、图、Trie树
- 十个算法：递归、排序、二分查找、搜索、哈希算法、贪心算法、分治算法、回溯算法、动态规划、字符串匹配算法

- 不要为了学习而学习，而是**要学习它的“来历”“自身的特点”“适合解决的问题”以及“实际的应用场景”**。

## 课后题：请思考一下你自己学习这个专栏的方法，你在之前学习数据结构和算法的过程中，遇到过什么样的困难或者疑惑吗？

- 这篇文章就是方法的一部分，在每一讲学完以后都会写成这样一块的总结，另外每天在LeetCode两道题
- 困难与疑惑真的是在于总感觉代码写不出来，想想挺对，一写就错

# 03讲复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗

- **复杂度分析是整个算法学习的精髓，只要掌握了它，数据结构和算法的内容基本上就掌握了一半**。
- 监控得到的运行时间受限于测试环境，测试数据，无法真正体现复杂度，因此我们需要一个不用具体测试数据，可以粗略估计算法的执行效率的方法

![img](http://ww3.sinaimg.cn/large/006tNc79ly1g5ues3fcx5j30vh031q31.jpg)

- 其中T(n)表示代码执行的时间；n表示数据规模的大小；f(n)表示每行代码执行的次数总和。因为这是一个公式，所以用f(n)来表示。公式中的O，表示代码的执行时间T(n)与f(n)表达式成正比。
- 这也就到了**大O时间复杂度**的本质，它不是代码真正的执行时间，而是**代码执行时间随数据规模增长的变化趋势**，真正名字应该是**渐进时间复杂度**（asymptotic time complexity），简称**时间复杂度**。

![img](http://ww4.sinaimg.cn/large/006tNc79ly1g5uezwa836j30vq0fwjti.jpg)

- 对于复杂度量级，我们可以粗略地分为两类，**多项式量级**和**非多项式量级**。其中，非多项式量级只有两个：O(2n)和O(n!)。
- 当数据规模n越来越大时，非多项式量级算法的执行时间会急剧增加，求解问题的执行时间会无限增长。所以，非多项式时间复杂度的算法其实是非常低效的算法。

## **O(1)**

- 由于大O表示的是代码执行时间的变化趋势，因此O(1)其实很好理解，就是时间是定死的
- **一般情况下，只要算法中不存在循环语句、递归语句，即使有成千上万行的代码，其时间复杂度也是Ο(1)**。

## **O(logn)、O(nlogn)**

- 不管是以2为底、以3为底，还是以10为底，我们可以把所有对数阶的时间复杂度都记为O(logn)，因为log3n就等于log32 * log2n，O(log3n) = O(C * log2n)，**在采用大O标记复杂度的时候，可以忽略系数，即O(Cf(n)) = O(f(n))**

## 空间复杂度

- 时间复杂度的全称是**渐进时间复杂度**，**表示算法的执行时间与数据规模之间的增长关系**。类比一下，空间复杂度全称就是**渐进空间复杂度**（asymptotic space complexity），**表示算法的存储空间与数据规模之间的增长关系**。

## 复杂度增进曲线

![img](http://ww3.sinaimg.cn/large/006tNc79ly1g5ufazepp3j30vq0hsjsq.jpg)

## 课后题：有人说，我们项目之前都会进行性能测试，再做代码的时间复杂度、空间复杂度分析，是不是多此一举呢？而且，每段代码都分析一下时间复杂度、空间复杂度，是不是很浪费时间呢？你怎么看待这个问题呢？

- 这个问题我觉得主要还是推出了时间复杂度，空间复杂度的概念后，我们在交流算法的时候有了一个交流的平台，我们能感性的了解到算法中的好坏，效率的高低
- 对于真正投入使用的时候，肯定实际测试要测，复杂度分析也要做

# 04讲复杂度分析（下）：浅析最好、最坏、平均、均摊时间复杂度
## 加权平均时间复杂度 = 平均时间复杂度 = 期望时间复杂度
```c++
// n表示数组array的长度
int find(int[] array, int n, int x) {
  int i = 0;
  int pos = -1;
  for (; i < n; ++i) {
    if (array[i] == x) {
       pos = i;
       break;
    }
  }
  return pos;
}
```

- 我们在长度为n的数组里搜索x的时候，由于一旦找到就会退出循环，导致不是每次运行都会肯定走n次，因此需要引入平均时间复杂度概念
- 要查找的变量x在数组中的位置，有n+1种情况：**在数组的0～n-1位置中**和**不在数组中**。我们把每种情况下，查找需要遍历的元素个数累加起来，然后再除以n+1，就可以得到需要遍历的元素个数的平均值，即：

![img](http://ww2.sinaimg.cn/large/006tNc79ly1g5umhf1q4oj30vm05y74l.jpg)

- 我们现在假设在数组与不在数组里的概率都是1/2，x出现在数组中每个位置的可能性都是1/n，这样，在搜索数组里的数据的时候，x出现在数组里的概率就是1/(2n)，x不出现在数组里的概率就是1/2
- 这里我的理解方式就是，x要能出现在数组里，前提条件就是先有了出现在数组里的那个可能性2/1，在此基础上才有了接下来来的1/n
- 现在的平均复杂度就是：

![img](http://ww1.sinaimg.cn/large/006tNc79ly1g5umqo2aukj30jy05yglq.jpg)

## 均摊时间复杂度

### 举例：

```c++
 // array表示一个长度为n的数组
 // 代码中的array.length就等于n
 int[] array = new int[n];
 int count = 0;
 
 void insert(int val) {
    if (count == array.length) {
       int sum = 0;
       for (int i = 0; i < array.length; ++i) {
          sum = sum + array[i];
       }
       array[0] = sum;
       count = 1;
    }

    array[count] = val;
    ++count;
 }
```

- 这是一个插入函数，两种情况：
  - count == array.length，count记录者当前插入到第几位，当count == len的时候，也就意味着数组里元素被插满了，此时便会遍历整个数组，求和，输入到首位。并令count = 1，等待下一次循环
  - 正常情况下赋值，count++
### 加权平均时间复杂度
- 假设数组的长度是n，根据数据插入的位置的不同，我们可以分为n种情况，每种情况的时间复杂度是O(1)。除此之外，还有一种“额外”的情况，就是在数组没有空闲空间时插入一个数据，这个时候的时间复杂度是O(n)。而且，这n+1种情况发生的概率一样，都是1/(n+1)。所以，根据加权平均的计算方法，我们求得的平均时间复杂度就是：

![img](http://ww4.sinaimg.cn/large/006tNc79ly1g5un8bxrz3j30vq04c0sx.jpg)

### 均摊时间复杂度

- 我们可以注意到一个规律，每次进行完O(n)的操作后，由于count回到了1，下面的n - 1个操作都是O(1)复杂度的
- 在此规律上，我们可以把耗时长的那个O(n)操作平均分配下去，这样平均下去，等同于每次操作都是O(1)【2次】
- 这样来看，时间复杂度就是O(1)
- 因此，均摊时间复杂度等同于就是特殊的时间复杂度算法，本身没有什么特别之处

## 课后题：你可以用今天学习的知识，来分析一下下面这个add()函数的时间复杂度。

```c++
// 全局变量，大小为10的数组array，长度len，下标i。
int array[] = new int[10]; 
int len = 10;
int i = 0;

// 往数组中添加一个元素
void add(int element) {
   if (i >= len) { // 数组空间不够了
     // 重新申请一个2倍大小的数组空间
     int new_array[] = new int[len*2];
     // 把原来array数组中的数据依次copy到new_array
     for (int j = 0; j < len; ++j) {
       new_array[j] = array[j];
     }
     // new_array复制给array，array现在大小就是2倍len了
     array = new_array;
     len = 2 * len;
   }
   // 将element放到下标为i的位置，下标i加一
   array[i] = element;
   ++i;
}
```

- 该算法的最好情况时间复杂度(best case time complexity)为O(1);
- 最坏情况时间复杂度(worst case time complexity)为O(n);
- 平均情况时间复杂度(average case time complexity)为O(1);
- 时间复杂度感觉还是没必要这么复杂，像这道题，只有一种情况会是O(n)，其他情况都肯定是O(1)，没有纠结的必要

# 05讲数组：为什么很多编程语言中数组都从0开始编号

- **数组（Array）是一种线性表数据结构。它用一组连续的内存空间，来存储一组具有相同类型的数据。**
- **线性表**（Linear List）。顾名思义，线性表就是数据排成像一条线一样的结构。每个线性表上的数据最多只有前和后两个方向。其实除了数组，链表、队列、栈等也是线性表结构。【线性表只有前后有联系】

![img](http://ww3.sinaimg.cn/large/006tNc79ly1g5unrmu5wrj30vq0n5acy.jpg)

- 与之相反的，在非线性表中，数据不是简单的前后关系

![img](http://ww4.sinaimg.cn/large/006tNc79ly1g5unso9trfj30vq0k7q4w.jpg)

- **连续的内存空间和相同类型的数据**。
- 不精确：链表适合插入、删除，时间复杂度O(1)；数组适合查找，查找时间复杂度为O(1)

- 精确：数组是适合查找操作，但是查找的时间复杂度并不为O(1)。即便是排好序的数组，你用二分查找，时间复杂度也是O(logn)。所以，正确的表述应该是，数组支持随机访问，根据下标随机访问的时间复杂度为O(1)。

- 数组删除的优化：将多次删除操作集中在一起执行，每次删除都是标记一待删除的数据，真正的删除等到内存不够的时候一口气进行，同时这也是java中的JVM删除

## 数组越界：黄金体验镇魂曲--永远无法到达的彼岸

```c++
int main(int argc, char* argv[]){
    int i = 0;
    int arr[3] = {0};
    for(; i<=3; i++){
        arr[i] = 0;
        printf("hello world\n");
    }
    return 0;
}
```

- 数组其实就是一块连续的内存，当我们越界的时候就会访问到其他内存空间
- 函数体内的局部变量存在栈上，且是连续压栈。在Linux进程的内存布局中，栈区在高地址空间，从高向低增长。变量i和arr在相邻地址，且i比arr的地址大，所以arr越界正好访问到i。当然，前提是i和arr元素同类型，否则那段代码仍是未决行为。
- 组越界在C语言中是一种未决行为，并没有规定数组访问越界时编译器应该如何处理。因为，访问数组的本质就是访问一段连续内存，只要数组通过偏移计算得到的内存地址是可用的，那么程序就可能不会报任何错误。
- 当然这个具体还是要看编译器与电脑具体情况，在我的CodeRunner上就是非常普通的崩溃了，在打印三次之后
- 总之，如果是在符合上述入栈规则的编译器中使用的话，就会出现无限打印的情况
- 因为arr[3]访问到的就是是i的地址，等于就是不停的在修改i的值，自然会导致无限循环
- 数组寻址公示：a[i]_address = base_address + i * data_type_size 

# 数组编号为什么从0开始，而不是从1开始

- 我们已经知道在内存里面不存在真正的数组，只有一段内存，我们有的只是首地址以及单位长度
- 因此下标其实描述的是数组的编译量，也就是从首地址开始的偏移程度
- 当我们的下标是从0开始的时候，我们的寻址公式是：a[i]_address = base_address + i * data_type_size 
- 而当我们的下标是从1开始的时候，我们的寻址公式就会变成：a[k]_address = base_address + (k-1)*type_size
- 这样多了一个减法操作，对于CPU来说，就多了一个减法指令

## 课后题

### 前面我基于数组的原理引出JVM的标记清除垃圾回收算法的核心理念。我不知道你是否使用Java语言，理解JVM，如果你熟悉，可以在回顾下你理解的标记清除垃圾回收算法。

- 大多数主流虚拟机采用可达性分析算法来判断对象是否存活，在标记阶段，会遍历所有 GC ROOTS，将所有 GC ROOTS 可达的对象标记为存活。只有当标记工作完成后，清理工作才会开始。
- 不足：1.效率问题。标记和清理效率都不高，但是当知道只有少量垃圾产生时会很高效。2.空间问题。会产生不连续的内存空间碎片。

### 前面我们讲到一维数组的内存寻址公式，那你可以思考一下，类比一下，二维数组的内存寻址公式是怎样的呢？

- 对于 m * n 的数组，a [ i ][ j ] (i < m,j < n)的地址为：address = base_address + ( i * n + j) * type_size
- 